Good Evening, my name is Lance, I am the CTO of DDROne and today I will be your presenter

for hardware.

1. What AI Hardware Means

AI hardware refers to the physical components of a computer system that are specially designed or optimized to run artificial intelligence (AI) workloads — especially machine learning (ML) and deep learning (DL) models. Examples include:
Recognizing faces in photos,
Understanding speech, or
Generating text and images (like ChatGPT or DALL·E).

2. Key Hardware Components in AI Sytems

We have CPUs, GPUs, and many more
 
First off, we CPUs
- Role: General-purpose processor; controls all other components.
- Strength: Flexibility — can handle all types of operations.
- Weakness: Not optimized for parallel processing (slow for large neural networks).
- Use case: Preprocessing data, coordinating other processors.
  
Then GPUs
- Role: Performs parallel computations — hundreds or thousands of cores work simultaneously.
- Strength: Excellent for matrix and vector operations common in deep learning.
- Weakness: High power consumption, expensive.
- Use case: Training and inference of deep neural networks.
  
Then we have TPUs
- Role: Custom processor built by Google specifically for TensorFlow and neural networks.
- Strength: Extremely fast at tensor (matrix) calculations.
- Use case: Cloud-based AI tasks like natural language processing (NLP) or computer vision.

And here is another type of hardware, that is NPUs
- Role: Specialized chips (like those in smartphones or embedded devices) that accelerate AI workloads.
- Strength: Energy efficient and optimized for on-device inference (edge AI).
- Use case: AI on mobile devices, IoT, autonomous systems.
  
Now let’s move on to GPU componentry, GPUs are made up of many components like SMs, Cache, CUDA, Tensor, and RT cores….







--> Since I found an auto-caption feature on CapCut (recommended to me by a Friend) i decided to do it freestyle
