Human-Computer Interaction (HCI) and UX/UI Research leverages RL to create interfaces that is specifically catered to an individual over time, rather than presenting a static design.


1. Model-Based RL for User-Adaptive Interfaces:
- Focus: Building an internal model of the user. Unlike model-free RL which purely learns through trial and error, model-based RL uses simulation to simulate the consequences of an adaptation before applying it.
- Goal: To develop a planning algorithm that not only adapt, but are aware of the cost of change.


2. Interactive Reinforcement Learning (IRL) for Feedback:
- Focus: To make the ai agent learn faster by incorporating direct human guidance during the learning process. Instead of waiting for a high-level reward signal, the agent can receive real time advice, corrections, or demonstrations from the user.
- Goal: To research on how to extract and fuse implicit feedback (e.g eye tracking, facial expression, voice tones, e.t.c) with explicit feedback.